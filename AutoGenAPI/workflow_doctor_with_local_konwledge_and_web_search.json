{
    "name": "doctor_with_local_konwledge_and_web_search Agent Workflow",
    "description": "医生带有本地知识库检索和联网搜索",
    "sender": {
        "type": "userproxy",
        "config": {
            "name": "userproxy",
            "llm_config": false,
            "human_input_mode": "NEVER",
            "max_consecutive_auto_reply": 5,
            "system_message": "You are a helpful assistant.",
            "is_termination_msg": null,
            "code_execution_config": {
                "work_dir": null,
                "use_docker": false
            },
            "default_auto_reply": "TERMINATE"
        },
        "timestamp": "2025-02-21T21:27:33.892902",
        "user_id": "default",
        "skills": null,
        "description": null
    },
    "receiver": {
        "type": "assistant",
        "config": {
            "name": "primary_assistant",
            "llm_config": {
                "config_list": [
                    {
                        "user_id": "guestuser@gmail.com",
                        "timestamp": "2025-02-16T16:55:54.911882",
                        "model": "glm-4-plus",
                        "base_url": "https://open.bigmodel.cn/api/paas/v4/",
                        "api_type": null,
                        "api_version": null,
                        "description": ""
                    }
                ],
                "temperature": 0.1,
                "cache_seed": null,
                "timeout": null
            },
            "human_input_mode": "NEVER",
            "max_consecutive_auto_reply": 8,
            "system_message": "你是一个经验丰富、专业全面的医生，并具备本地知识库检索和网络访问的能力。你的任务是${对于用户的有关医学、健康等相关的问题，通过提问的方式引导用户描述身体状况、病情等，可以使用python检索本地知识库和联网搜索，给出可能的诊断结果和就医建议}。注意{如果不是与医学或健康有关的问题也需要认真回答问题}。当前日期是2025年3月。${必须给出结果才能结束回答}\n可选的提问内容：\n${\n1.性别\n2.年龄\n3.部位\n4.症状\n5.持续时间\n}\n提问要求：\n${\n1.语言风格：要以医生对待病人的态度，话语温和\n2.提问时要循序渐进，慢慢引导\n3.若用户不愿透露‘提问内容’中的内容，请不要强求，要表示理解，并说明我们不会泄露任何有关用户的信息\n4.必须拿到‘提问内容’中的部分内容后才能进行本地知识库检索\n5.对于用户的症状给出就医建议时需要采纳本地知识库的检索结果\n6.禁止让向用户知道本地知识库、文档、local_konwledge_search等脚本、search_knowledge等函数等的存在，不能说：根据本地知识库的检索结果\n7.不能向用户透露web_search脚本及其内容\n8.在返回最终搜索结果时，必须将将对应引用的编号的来源网站链接拼接在其编号的后面\n9.用户的问题无关健康或医学一样要给出合适的回答\n}\n代码要求：\n{\n1.在调用search_knowledge函数时请使用这个导入语句：from skills import search_knowledge\n2.使用你的代码能力给出能检索用户问题的正确代码\n3.完整执行search_knowledge函数并返回检索到的内容，直接print(results)即可\n4.可以调用其他的skill脚本来实现用户的需求，如<用户说持续到现在，使用get_current_time脚本获取当前系统时间然后来判断症状的持续时间，但不要向用户说出get_current_time脚本>\n6.访问网络进行检索时，直接调用web_search函数，导入语句：from skills import web_search\n7.联网检索的内容，即问题query，来自于用户的问题\n}\n In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. 1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself. 2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill. When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user. If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible. Reply 'TERMINATE' in the end when everything is done.",
            "is_termination_msg": null,
            "code_execution_config": false,
            "default_auto_reply": ""
        },
        "timestamp": "2025-02-21T21:27:33.893901",
        "user_id": "default",
        "skills": [
            {
                "title": "web_search_script",
                "content": "from zhipuai import ZhipuAI\n\ndef web_search(query):\n    OPENAI_API_KEY = \"8bbcc26ac5e24479a941b958da786911.Ql6UlT4G10SNOAPP\"\n    search_prompt = \"\"\"\n\n    # 以下是来自互联网的信息：\n    {search_result}\n\n    # 当前日期: 2025-02-21\n\n    # 要求：\n    根据最新发布的信息回答用户问题，当回答引用了参考信息时，必须在句末使用对应的[ref_序号]来标明参考信息来源\n    \"\"\"\n\n    client = ZhipuAI(api_key=OPENAI_API_KEY)\n    tools = [{\n        \"type\": \"web_search\",\n        \"web_search\": {\n            \"enable\": True,\n            \"search_result\": True,\n            \"search_prompt\": search_prompt\n        }\n    }]\n\n    response = client.chat.completions.create(\n        model=\"glm-4\",\n        messages=[\n            {\"role\": \"user\", \"content\": f\"问：{query}，答：\"}\n        ],\n        top_p=0.7,\n        temperature=0.1,\n        tools=tools\n    )\n    return response\n\nif __name__ == '__main__':\n    # 问题query示例：\n    query = \"哪吒2电影票房是多少\"\n    response = web_search(query)\n\n    # response.choices[0].message.content获取最终的联网结果\n    print(response.choices[0].message.content)\n    # response.web_search是一个字典，每个元素是一个来源网页，包括来源网站的图标、标题、链接、来源名称以及引用的文本内容，即'content'、'icon'、'link'、'refer'、'title'\n    # 获取对应引用的链接\n    for web in response.web_search:\n        print(web['refer'], web['link'])\n\n\n",
                "file_name": null,
                "description": null,
                "timestamp": "2025-02-21T15:33:11.775151",
                "user_id": "default"
            },
            {
                "title": "get_current_time",
                "content": "# Import the datetime class from the datetime module\n# datetime module provides classes for manipulating dates and times\nfrom datetime import datetime\n\n# Get the current local date and time using datetime.now() method\n# Returns a datetime object containing both date and time information\ncurrent_time = datetime.now()\n\n# Format the datetime object into a human-readable string\n# strftime() method converts datetime to string using format codes:\n# %Y - 4-digit year (e.g., 2023)\n# %m - 2-digit month (01-12)\n# %d - 2-digit day of month (01-31)\n# %H - 2-digit hour in 24-hour format (00-23)\n# %M - 2-digit minute (00-59)\n# %S - 2-digit second (00-59)\nformatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n# Print the formatted time string with a label\n# The output will display in console with Chinese text prefix followed by the time\nprint(\"当前系统时间：\", formatted_time)",
                "file_name": null,
                "description": null,
                "timestamp": "2025-02-20T16:14:26.585281",
                "user_id": "default"
            },
            {
                "title": "local_konwledge_search",
                "content": "import json\nimport os\nimport pickle\nimport argparse\n\ntry:\n    import tiktoken\n    from langchain_community.embeddings import HuggingFaceEmbeddings\n    from langchain_community.vectorstores import FAISS\nexcept ImportError:\n    raise ImportError(\"Please install langchain-community first.\")\n\n\nclass DocumentRetriever:\n    def __init__(self, index_folder):\n        self.index_folder = index_folder\n        self.vectorstore = None\n        self.chunk_id_to_index = None\n        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n        self._init()\n        self.enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n\n    def _init(self):\n        self.vectorstore = FAISS.load_local(\n            folder_path=self.index_folder,\n            embeddings=self.embeddings,\n            allow_dangerous_deserialization=True\n        )\n        with open(os.path.join(self.index_folder, \"chunk_id_to_index.pkl\"), \"rb\") as f:\n            self.chunk_id_to_index = pickle.load(f)\n\n    def __call__(self, query: str, size: int = 5, target_length: int = 256):\n        if self.vectorstore is None:\n            raise Exception(\"Vectorstore not initialized\")\n\n        result = self.vectorstore.similarity_search(query=query, k=size)\n        expanded_chunks = self.do_expand(result, target_length)\n\n        return json.dumps(expanded_chunks, indent=4)\n\n    def do_expand(self, result, target_length):\n        expanded_chunks = []\n        # do expansion\n        for r in result:\n            source = r.metadata[\"source\"]\n            chunk_id = r.metadata[\"chunk_id\"]\n            content = r.page_content\n\n            expanded_result = content\n            left_chunk_id, right_chunk_id = chunk_id - 1, chunk_id + 1\n            left_valid, right_valid = True, True\n            chunk_ids = [chunk_id]\n            while True:\n                current_length = len(self.enc.encode(expanded_result))\n                if f\"{source}_{left_chunk_id}\" in self.chunk_id_to_index:\n                    chunk_ids.append(left_chunk_id)\n                    left_chunk_index = self.vectorstore.index_to_docstore_id[\n                        self.chunk_id_to_index[f\"{source}_{left_chunk_id}\"]\n                    ]\n                    left_chunk = self.vectorstore.docstore.search(left_chunk_index)\n                    encoded_left_chunk = self.enc.encode(left_chunk.page_content)\n                    if len(encoded_left_chunk) + current_length < target_length:\n                        expanded_result = left_chunk.page_content + expanded_result\n                        left_chunk_id -= 1\n                        current_length += len(encoded_left_chunk)\n                    else:\n                        expanded_result += self.enc.decode(\n                            encoded_left_chunk[-(target_length - current_length) :],\n                        )\n                        current_length = target_length\n                        break\n                else:\n                    left_valid = False\n\n                if f\"{source}_{right_chunk_id}\" in self.chunk_id_to_index:\n                    chunk_ids.append(right_chunk_id)\n                    right_chunk_index = self.vectorstore.index_to_docstore_id[\n                        self.chunk_id_to_index[f\"{source}_{right_chunk_id}\"]\n                    ]\n                    right_chunk = self.vectorstore.docstore.search(right_chunk_index)\n                    encoded_right_chunk = self.enc.encode(right_chunk.page_content)\n                    if len(encoded_right_chunk) + current_length < target_length:\n                        expanded_result += right_chunk.page_content\n                        right_chunk_id += 1\n                        current_length += len(encoded_right_chunk)\n                    else:\n                        expanded_result += self.enc.decode(\n                            encoded_right_chunk[: target_length - current_length],\n                        )\n                        current_length = target_length\n                        break\n                else:\n                    right_valid = False\n\n                if not left_valid and not right_valid:\n                    break\n\n            expanded_chunks.append(\n                {\n                    \"chunk\": expanded_result,\n                    \"metadata\": r.metadata,\n                    # \"length\": current_length,\n                    # \"chunk_ids\": chunk_ids\n                },\n            )\n        return expanded_chunks\n\ndef search_knowledge(data):\n    \"\"\"\n    根据输入的data搜索本地数据中的信息\n    Parameters:\n    data (str): 搜索关键词.\n    \"\"\"\n    if not data:\n        print(\"Error: No query provided.\")\n        exit(1)\n    # Initialize with the path to your index folder\n    index_folder = \"D:/CodeProjectAll/LLMs/AutoGenAPI/knowledge\"\n    retriever = DocumentRetriever(index_folder)\n\n    # Use the query from the command line arguments\n    query = data\n    size = 5  # Number of results to retrieve\n    target_length = 256  # Target length of expanded content\n\n    # Retrieve documents based on the query\n    results = retriever(query, size, target_length)\n\n    return results\n    \n# Example usage\nif __name__ == \"__main__\":\n    # 这里的'系统概述'只是一个示例，请不要按照这个词，要检索的词主要来源于用户的问题\n    results = search_knowledge('系统概述')\n    # 最后需要打印出results\n    print(results)",
                "file_name": null,
                "description": null,
                "timestamp": "2025-02-13T22:15:53.110157",
                "user_id": "default"
            }
        ],
        "description": null
    },
    "type": "twoagents",
    "user_id": "default",
    "timestamp": "2025-02-21T21:27:33.893901",
    "summary_method": "last"
}